---
title: "BlackFriday_Pravat"
author: "Pravat"
date: "23 April 2019"
output:
  html_document: default
  pdf_document: default
---

# Global setup and Library import
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(data.table)
library(caret)          # To enable training with CV.
library(ggplot2)        # For visualization
library(e1071)          # For skewness
library(plyr)           # Iterative operations
```

# Introduction

The dataset here is a sample of the transactions made in a retail store. The store wants to know better the customer purchase behaviour against different products. Specifically, here the problem is a regression problem where we are trying to predict the dependent variable (the amount of purchase) with the help of the information contained in the other variables.

Classification problem can also be settled in this dataset since several variables are categorical, and some other approaches could be "Predicting the age of the consumer" or even "Predict the category of goods bought". This dataset is also particularly convenient for clustering and maybe find different clusters of consumers within it.

# CONTENT:

Both Dataset have the following fields, except Purchase - which is not available in BlackFriday_test.csv.

1. User_ID: Unique ID of the customer
2. Product_ID: Unique ID of the product sold/bought
3. Gender: Gender of the Customer
4. Age: Age group of the customer
5. Occupation: Customer occupation category
6. City_Category: Category of the city
7. Stay_In_Current_City_Years: Number of years the Customer has been staying in the city
8. Marital_Status: Customer's marital status
9. Product_Category_1: Parent category of the product
10. Product_Category_2: Sub-category on the Product_Category_1
11. Product_Category_3: Sub-category on the Product_Category_2
12. Purchase: Target variable. Monitary amount of purchase

# Useful Functions

```{r Useful functions}
# Function to split the dataset randomly with a given propert
splitdt <- function(dt, test_proportion=0.2, seed=NULL){
  if(!is.null(seed)) set.seed(seed)
  
  train_index <- sample(nrow(dt), floor(nrow(dt)*(1-test_proportion)), replace = FALSE)
  trainset<-dt[train_index]
  testset<-dt[-train_index]
  
  return(list(train=trainset, test=testset))
}

# MAPE metric
mape<-function(real,predicted){
  return(mean(abs((real-predicted)/real)))
}
```

# Data Reading and preparation

The dataset is offered in two separated fields, one for the training and another one for the test set. 

```{r Load Data}
original_training_data = fread(file = file.path("BlackFriday_train.csv"))
original_test_data = read.csv(file = file.path("BlackFriday_test.csv"))
```

To avoid applying the Feature Engineering process two times (once for training and once for test), you can just join both datasets (using the `rbind` function), apply your FE and then split the datasets again. However, if we try to do join the two dataframes as they are, we will get an error because they do not have the same columns: `test_data` does not have a column `Purchase`. Therefore, we first create this column in the test set and then we join the data

```{r Joinning datasets}
# Create the column Purchase in test set and assign the value to 0
original_test_data$Purchase <- 0

# Create the column dataType in both train and test set and assign the value 'train' & 'test'. This will help us to split the dataset from the dataType, not by position
original_training_data$dataType <- "train"
original_test_data$dataType <- "test"

# Join the two datasets
dataset <- rbind(original_training_data, original_test_data)
```

Let's now visualize the dataset to see where to begin
```{r Data Visualization}
summary(dataset)
```
We can see some problems just by taking a look to the summary: the dataset has missing values, there are some categorical columns codified as numeric, it has different scales for the feature values. In addition, we will take a deeper look to the data to detect more subtle issues: correlation between features, skewness in the feature values.
